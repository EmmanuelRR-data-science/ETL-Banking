{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Creación de un dashboard interactivo para visualizar el impacto de una campaña de marketing para un banco. Técnicas: Conexión a bases de datos en Google Cloud platform, modelado de datos, creación de visualizaciones interactivas y publicación en Looker Studio y Tableau. Dataset: Banking Dataset - Marketing Targets (Kaggle)"
      ],
      "metadata": {
        "id": "HRh9dcL8UWsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuraciones iniciales y preparación del dataset y entorno de Google Cloud Platform"
      ],
      "metadata": {
        "id": "YyB-5--cVaJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 1️⃣ Importar librerías\n",
        "# -------------------------------\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery"
      ],
      "metadata": {
        "id": "YkIIcVU7OmOs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 2️⃣ Configurar cliente BigQuery\n",
        "# -------------------------------\n",
        "# Descarga tu archivo de credenciales JSON de GCP y subelo a Colab\n",
        "# Reemplaza 'tu_clave.json' con el nombre de tu archivo\n",
        "client = bigquery.Client.from_service_account_json('etldatascience-1dd3397f3376.json')"
      ],
      "metadata": {
        "id": "YevrIV-VOqiz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 3️⃣ Leer dataset CSV de Kaggle\n",
        "# -------------------------------\n",
        "# Train dataset\n",
        "df_train = pd.read_csv('train.csv', sep=';')\n",
        "\n",
        "# Revisar primeras filas\n",
        "print(df_train.head())\n",
        "print(df_train.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgTIIrvnREM8",
        "outputId": "f6034737-f31e-47a2-b2a1-be566c2063e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age           job  marital  education default  balance housing loan  \\\n",
            "0   58    management  married   tertiary      no     2143     yes   no   \n",
            "1   44    technician   single  secondary      no       29     yes   no   \n",
            "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
            "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
            "4   33       unknown   single    unknown      no        1      no   no   \n",
            "\n",
            "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
            "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
            "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
            "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
            "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
            "4  unknown    5   may       198         1     -1         0  unknown  no  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45211 entries, 0 to 45210\n",
            "Data columns (total 17 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        45211 non-null  int64 \n",
            " 1   job        45211 non-null  object\n",
            " 2   marital    45211 non-null  object\n",
            " 3   education  45211 non-null  object\n",
            " 4   default    45211 non-null  object\n",
            " 5   balance    45211 non-null  int64 \n",
            " 6   housing    45211 non-null  object\n",
            " 7   loan       45211 non-null  object\n",
            " 8   contact    45211 non-null  object\n",
            " 9   day        45211 non-null  int64 \n",
            " 10  month      45211 non-null  object\n",
            " 11  duration   45211 non-null  int64 \n",
            " 12  campaign   45211 non-null  int64 \n",
            " 13  pdays      45211 non-null  int64 \n",
            " 14  previous   45211 non-null  int64 \n",
            " 15  poutcome   45211 non-null  object\n",
            " 16  y          45211 non-null  object\n",
            "dtypes: int64(7), object(10)\n",
            "memory usage: 5.9+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 4️⃣ Crear columnas adicionales para análisis\n",
        "# -------------------------------\n",
        "# Objetivo binario\n",
        "df_train['y_binary'] = df_train['y'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Duración en minutos\n",
        "df_train['duration_min'] = df_train['duration'] / 60"
      ],
      "metadata": {
        "id": "HWdnXQNnRL7p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 5️⃣ Guardar CSV limpio\n",
        "# -------------------------------\n",
        "df_train.to_csv('train_clean.csv', index=False)\n",
        "print(\"CSV limpio listo para BigQuery\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOO89c3wRPvx",
        "outputId": "b520fbce-bbdd-46f8-b862-529ed88b08ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV limpio listo para BigQuery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 6️⃣ Subir DataFrame a BigQuery\n",
        "# -------------------------------\n",
        "# Configurar proyecto y dataset en GCP\n",
        "project_id = 'etldatascience'\n",
        "dataset_id = 'bank_marketing'\n",
        "table_id = f'{project_id}.{dataset_id}.marketing_targets'\n",
        "\n",
        "for col in [\"default\", \"housing\", \"loan\", \"y\"]:\n",
        "    df_train[col] = df_train[col].map({\"yes\": True, \"no\": False})\n",
        "\n",
        "# Subir datos\n",
        "job = client.load_table_from_dataframe(df_train, table_id)\n",
        "job.result()  # Espera a que termine la carga\n",
        "print(\"Datos cargados a BigQuery correctamente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvRZPxmdRTwE",
        "outputId": "2e8b84b6-0b4c-45e2-87aa-797f01f1dab2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos cargados a BigQuery correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 7️⃣ Consultas SQL\n",
        "# -------------------------------\n",
        "# Total de contactos\n",
        "query_total = f\"\"\"\n",
        "SELECT COUNT(*) AS total_contacts\n",
        "FROM `{table_id}`\n",
        "\"\"\"\n",
        "total_contacts = client.query(query_total).to_dataframe()\n",
        "print(\"Total de contactos:\\n\", total_contacts)\n",
        "\n",
        "# Tasa de conversión\n",
        "query_conversion = f\"\"\"\n",
        "SELECT SUM(y_binary)/COUNT(*) AS conversion_rate\n",
        "FROM `{table_id}`\n",
        "\"\"\"\n",
        "conversion_rate = client.query(query_conversion).to_dataframe()\n",
        "print(\"Tasa de conversión:\\n\", conversion_rate)\n",
        "\n",
        "# Duración promedio por campaña\n",
        "query_duration = f\"\"\"\n",
        "SELECT campaign, AVG(duration_min) AS avg_duration\n",
        "FROM `{table_id}`\n",
        "GROUP BY campaign\n",
        "ORDER BY avg_duration DESC\n",
        "\"\"\"\n",
        "avg_duration = client.query(query_duration).to_dataframe()\n",
        "print(\"Promedio duración por campaña:\\n\", avg_duration.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuO_1KpaObod",
        "outputId": "d4f95295-b0b8-4fc1-de10-a2fe54ea9ad8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de contactos:\n",
            "    total_contacts\n",
            "0          180844\n",
            "Tasa de conversión:\n",
            "    conversion_rate\n",
            "0         0.116985\n",
            "Promedio duración por campaña:\n",
            "    campaign  avg_duration\n",
            "0        55     18.233333\n",
            "1         2      4.588767\n",
            "2         3      4.527314\n",
            "3         1      4.350894\n",
            "4         4      4.219908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo predictivo con Machine Learning"
      ],
      "metadata": {
        "id": "LCx3ojsgVmWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 1) Imports e instalación opcional\n",
        "# =========================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score, f1_score,\n",
        "                             precision_recall_curve, classification_report,\n",
        "                             confusion_matrix)"
      ],
      "metadata": {
        "id": "-PBAkOkKV661"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 2) Conexión a BigQuery\n",
        "# =========================================\n",
        "# Datos previamente usados:\n",
        "SERVICE_ACCOUNT_JSON = \"etldatascience-1dd3397f3376.json\"\n",
        "PROJECT_ID = \"etldatascience\"\n",
        "DATASET = \"bank_marketing\"\n",
        "TABLE = \"marketing_targets\"\n",
        "TABLE_ID = f\"{PROJECT_ID}.{DATASET}.{TABLE}\"\n",
        "\n",
        "client = bigquery.Client.from_service_account_json(SERVICE_ACCOUNT_JSON)"
      ],
      "metadata": {
        "id": "9oPtv960V_Fi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 3) Cargar datos desde BigQuery\n",
        "#    (usamos todas las columnas y luego elegimos features)\n",
        "# =========================================\n",
        "query = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{TABLE_ID}`\n",
        "\"\"\"\n",
        "df = client.query(query).to_dataframe()\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head(3))\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMfJn6jIWYld",
        "outputId": "c488f891-196e-4cda-c9b5-899e1e7c453a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (180844, 19)\n",
            "   age           job  marital  education  default  balance  housing   loan  \\\n",
            "0   58    management  married   tertiary    False     2143     True  False   \n",
            "1   44    technician   single  secondary    False       29     True  False   \n",
            "2   33  entrepreneur  married  secondary    False        2     True   True   \n",
            "\n",
            "   contact  day month  duration  campaign  pdays  previous poutcome      y  \\\n",
            "0  unknown    5   may       261         1     -1         0  unknown  False   \n",
            "1  unknown    5   may       151         1     -1         0  unknown  False   \n",
            "2  unknown    5   may        76         1     -1         0  unknown  False   \n",
            "\n",
            "   y_binary  duration_min  \n",
            "0         0      4.350000  \n",
            "1         0      2.516667  \n",
            "2         0      1.266667  \n",
            "age               Int64\n",
            "job              object\n",
            "marital          object\n",
            "education        object\n",
            "default         boolean\n",
            "balance           Int64\n",
            "housing         boolean\n",
            "loan            boolean\n",
            "contact          object\n",
            "day               Int64\n",
            "month            object\n",
            "duration          Int64\n",
            "campaign          Int64\n",
            "pdays             Int64\n",
            "previous          Int64\n",
            "poutcome         object\n",
            "y               boolean\n",
            "y_binary          Int64\n",
            "duration_min    float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 4) Definir target y escenarios de features\n",
        "#    Escenario recomendado: PRE-CALL (sin 'duration' ni 'duration_min')\n",
        "# =========================================\n",
        "TARGET = \"y_binary\"  # 1 si convierte, 0 si no\n",
        "USE_DURATION = False # cambia a True si quieres el escenario post-call\n",
        "\n",
        "# Categóricas del dataset original\n",
        "cat_cols = [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\n",
        "            \"contact\",\"month\",\"poutcome\"]\n",
        "# Numéricas del dataset original (sin leakage)\n",
        "num_cols = [\"age\",\"balance\",\"day\",\"campaign\",\"pdays\",\"previous\"]\n",
        "\n",
        "# Si quieres escenario post-call (incluye duración conocida tras la llamada)\n",
        "if USE_DURATION:\n",
        "    # Puedes usar 'duration_min' (tu columna calculada); evita mezclar ambas\n",
        "    num_cols = num_cols + [\"duration_min\"]\n",
        "\n",
        "# Drop de filas con target nulo (por si acaso)\n",
        "df = df.dropna(subset=[TARGET]).copy()\n",
        "\n",
        "X = df[cat_cols + num_cols]\n",
        "y = df[TARGET].astype(int)\n",
        "\n",
        "# Checar balance de clases\n",
        "print(\"Distribución de y:\", y.value_counts(normalize=True).round(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkjNfvPDWeyV",
        "outputId": "1640032d-3075-41b4-b6f5-516c3d8d6611"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de y: y_binary\n",
            "0    0.883\n",
            "1    0.117\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 5) Preprocesamiento: imputación + OHE + escalado\n",
        "# =========================================\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, num_cols),\n",
        "        (\"cat\", categorical_transformer, cat_cols),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "iAJvlVwfWkd4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 6) Train/Test split estratificado\n",
        "# =========================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Reemplazar cualquier pd.NA por np.nan de forma segura\n",
        "X_train = X_train.applymap(lambda x: np.nan if pd.isna(x) else x)\n",
        "X_test = X_test.applymap(lambda x: np.nan if pd.isna(x) else x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag4mJJteWpqN",
        "outputId": "aba21fea-0613-4543-fa64-88844d4c4d3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2786071077.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  X_train = X_train.applymap(lambda x: np.nan if pd.isna(x) else x)\n",
            "/tmp/ipython-input-2786071077.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  X_test = X_test.applymap(lambda x: np.nan if pd.isna(x) else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 7) Modelos base\n",
        "#    A) Regresión Logística\n",
        "# =========================================\n",
        "log_reg = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "# Validación cruzada con varias métricas\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\"roc_auc\":\"roc_auc\", \"pr_auc\":\"average_precision\", \"f1\":\"f1\"}\n",
        "\n",
        "cv_log = cross_validate(log_reg, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
        "print(\"\\n[LogReg] CV ROC-AUC: \", np.mean(cv_log[\"test_roc_auc\"]).round(4))\n",
        "print(\"[LogReg] CV PR-AUC : \", np.mean(cv_log[\"test_pr_auc\"]).round(4))\n",
        "print(\"[LogReg] CV F1     : \", np.mean(cv_log[\"test_f1\"]).round(4))\n",
        "\n",
        "# Fit y evaluación en test con threshold por defecto (0.5)\n",
        "log_reg.fit(X_train, y_train)\n",
        "proba_lr = log_reg.predict_proba(X_test)[:,1]\n",
        "print(\"\\n[LogReg] Test ROC-AUC:\", roc_auc_score(y_test, proba_lr).round(4))\n",
        "print(\"[LogReg] Test PR-AUC :\", average_precision_score(y_test, proba_lr).round(4))\n",
        "\n",
        "# Tuning de umbral para maximizar F1 (puedes cambiar por recall/precision balanceados)\n",
        "prec, rec, thr = precision_recall_curve(y_test, proba_lr)\n",
        "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
        "best_idx = np.argmax(f1s[:-1])  # thr tiene len = len(prec)-1\n",
        "best_thr = thr[best_idx]\n",
        "print(\"[LogReg] Mejor umbral F1:\", best_thr.round(3), \" | F1:\", f1s[best_idx].round(4))\n",
        "\n",
        "y_pred_lr = (proba_lr >= best_thr).astype(int)\n",
        "print(\"\\n[LogReg] Classification report (umbral optimizado)\")\n",
        "print(classification_report(y_test, y_pred_lr, digits=4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si42gozrWvM1",
        "outputId": "d8aecb50-bf5d-4107-e5fd-6812633524b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[LogReg] CV ROC-AUC:  0.7659\n",
            "[LogReg] CV PR-AUC :  0.3983\n",
            "[LogReg] CV F1     :  0.3757\n",
            "\n",
            "[LogReg] Test ROC-AUC: 0.7673\n",
            "[LogReg] Test PR-AUC : 0.4041\n",
            "[LogReg] Mejor umbral F1: 0.649  | F1: 0.4434\n",
            "\n",
            "[LogReg] Classification report (umbral optimizado)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9251    0.9323    0.9287     31938\n",
            "           1     0.4572    0.4304    0.4434      4231\n",
            "\n",
            "    accuracy                         0.8736     36169\n",
            "   macro avg     0.6912    0.6814    0.6860     36169\n",
            "weighted avg     0.8704    0.8736    0.8719     36169\n",
            "\n",
            "Confusion matrix:\n",
            " [[29776  2162]\n",
            " [ 2410  1821]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 7B) Random Forest (robusto con categóricas OHE)\n",
        "# =========================================\n",
        "rf = Pipeline(steps=[\n",
        "    (\"prep\", preprocess),\n",
        "    (\"clf\", RandomForestClassifier(\n",
        "        n_estimators=400,\n",
        "        max_depth=None,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=3,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "cv_rf = cross_validate(rf, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
        "print(\"\\n[RF] CV ROC-AUC: \", np.mean(cv_rf[\"test_roc_auc\"]).round(4))\n",
        "print(\"[RF] CV PR-AUC : \", np.mean(cv_rf[\"test_pr_auc\"]).round(4))\n",
        "print(\"[RF] CV F1     : \", np.mean(cv_rf[\"test_f1\"]).round(4))\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "proba_rf = rf.predict_proba(X_test)[:,1]\n",
        "print(\"\\n[RF] Test ROC-AUC:\", roc_auc_score(y_test, proba_rf).round(4))\n",
        "print(\"[RF] Test PR-AUC :\", average_precision_score(y_test, proba_rf).round(4))\n",
        "\n",
        "prec, rec, thr = precision_recall_curve(y_test, proba_rf)\n",
        "f1s = (2*prec*rec)/(prec+rec+1e-9)\n",
        "best_idx = np.argmax(f1s[:-1])\n",
        "best_thr_rf = thr[best_idx]\n",
        "print(\"[RF] Mejor umbral F1:\", best_thr_rf.round(3), \" | F1:\", f1s[best_idx].round(4))\n",
        "\n",
        "y_pred_rf = (proba_rf >= best_thr_rf).astype(int)\n",
        "print(\"\\n[RF] Classification report (umbral optimizado)\")\n",
        "print(classification_report(y_test, y_pred_rf, digits=4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yEzzLsUXsxc",
        "outputId": "5fa0b6dd-5a44-4591-89b3-6229a1087c89"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[RF] CV ROC-AUC:  0.9649\n",
            "[RF] CV PR-AUC :  0.8393\n",
            "[RF] CV F1     :  0.7658\n",
            "\n",
            "[RF] Test ROC-AUC: 0.98\n",
            "[RF] Test PR-AUC : 0.8977\n",
            "[RF] Mejor umbral F1: 0.57  | F1: 0.8295\n",
            "\n",
            "[RF] Classification report (umbral optimizado)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9773    0.9776    0.9774     31938\n",
            "           1     0.8306    0.8284    0.8295      4231\n",
            "\n",
            "    accuracy                         0.9602     36169\n",
            "   macro avg     0.9039    0.9030    0.9035     36169\n",
            "weighted avg     0.9601    0.9602    0.9601     36169\n",
            "\n",
            "Confusion matrix:\n",
            " [[31223   715]\n",
            " [  726  3505]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 8) Importancia de características\n",
        "#    A) Coeficientes de la Regresión Logística\n",
        "# =========================================\n",
        "# Obtenemos nombres de columnas transformadas:\n",
        "ohe = log_reg.named_steps[\"prep\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
        "feature_names = np.r_[num_cols, cat_feature_names]\n",
        "\n",
        "coefs = log_reg.named_steps[\"clf\"].coef_.ravel()\n",
        "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coefs})\n",
        "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
        "coef_top = coef_df.sort_values(\"abs_coef\", ascending=False).head(20)\n",
        "print(\"\\nTop 20 features (LogReg | |coef|):\\n\", coef_top[[\"feature\",\"coef\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmvLg618YvZ7",
        "outputId": "24c5e7aa-5c29-4019-aed5-3964e2731838"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 features (LogReg | |coef|):\n",
            "               feature      coef\n",
            "48   poutcome_success  1.711139\n",
            "41          month_mar  1.337901\n",
            "38          month_jan -1.026119\n",
            "44          month_oct  0.985393\n",
            "45          month_sep  0.857613\n",
            "43          month_nov -0.792029\n",
            "36          month_dec  0.749604\n",
            "35          month_aug -0.712786\n",
            "33    contact_unknown -0.710739\n",
            "39          month_jul -0.651656\n",
            "46   poutcome_failure -0.635720\n",
            "49   poutcome_unknown -0.600174\n",
            "31   contact_cellular  0.535785\n",
            "11        job_retired  0.498836\n",
            "42          month_may -0.486496\n",
            "14        job_student  0.429926\n",
            "47     poutcome_other -0.362090\n",
            "37          month_feb -0.329891\n",
            "9       job_housemaid -0.297021\n",
            "32  contact_telephone  0.288109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 9) Guardar artefactos (opcional)\n",
        "# =========================================\n",
        "import joblib, os\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "joblib.dump(log_reg, \"artifacts/model_logreg_pre.pkl\")\n",
        "joblib.dump(rf,      \"artifacts/model_rf_pre.pkl\")\n",
        "coef_top.to_csv(\"artifacts/top_features_logreg.csv\", index=False)\n",
        "print(\"\\nArtefactos guardados en carpeta 'artifacts/'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp8DWH0JVtyT",
        "outputId": "f2fa2c15-ab9e-4e4e-8bc1-ddaba563e905"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Artefactos guardados en carpeta 'artifacts/'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusión:**\n",
        "\n",
        "El análisis de la campaña de marketing muestra que los factores más determinantes para la conversión de clientes son los resultados de campañas previas exitosas (poutcome_success), el canal de contacto empleado (contact_cellular) y la estacionalidad reflejada en ciertos meses del año. Mientras que algunas variables demográficas como el tipo de empleo (job_student, job_retired) aportan información adicional, su impacto es menor. Estos hallazgos permiten identificar estrategias de segmentación más efectivas y priorizar recursos en clientes con mayor probabilidad de conversión, facilitando la toma de decisiones basada en datos para futuras campañas."
      ],
      "metadata": {
        "id": "rLxbPct-ZHa5"
      }
    }
  ]
}